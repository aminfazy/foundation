{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_fcnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrjcs/foundation_aiml/blob/master/mnist_fcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2IrTN4gCcew",
        "colab_type": "text"
      },
      "source": [
        "#basic fully connected neural network for mnist digit classification\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70EjjPgoKkB9",
        "colab_type": "text"
      },
      "source": [
        "## nice documentation is available at https://keras.io/\n",
        "## -- Keras provides in-built support to many datasets\n",
        "## -- such as MNIST (Modified National Institute of Standards and Technology database) @ http://yann.lecun.com/exdb/mnist/\n",
        "\t# database of handwritten digits\n",
        "\t# used  extensively in optical character recognition and machine learning research\n",
        "\t# training set of 60,000 examples, and a test set of 10,000 examples\n",
        "\t# digits have been size-normalized and centered in a fixed-size image\n",
        "\t# black and white digits\n",
        "\t# 28 x 28  pixels\n",
        "\t# Keras provides method to load MNIST data set\n",
        "  \n",
        "  > refer to # https://keras.io/datasets/#mnist-database-of-handwritten-digits for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKWVb27vAeL7",
        "colab_type": "code",
        "outputId": "8e59d0cb-156e-4ae9-b076-42365aef3338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# load MNIST data set\n",
        "from keras.datasets import mnist\t \t#dataset\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() \t#Keras function\n",
        "\n",
        "print (\"mnist data downloaded...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mnist data downloaded...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I33vNMnK1TZ",
        "colab_type": "text"
      },
      "source": [
        "### plot images...\n",
        "\n",
        "> subplot function is being used\n",
        "\n",
        "> nice documentation is available on the official webpage of matplotlib\n",
        "\n",
        "> arguments to subplot functions are number of rows, number of columns and number of subplots in the plot\n",
        "\n",
        "> comma is mandatory if values are greater than or equal to 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuUhUPFTAjbq",
        "colab_type": "code",
        "outputId": "fe25c76a-e861-499b-9a4f-c9f40a6896e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# this code cell only for visualization\n",
        "# comment if do not want to print\n",
        "\n",
        "import matplotlib.pyplot as plt\t\t\t#to plot images\n",
        "\n",
        "plt.subplot(221)\t\n",
        "plt.imshow(X_train[50], cmap=plt.get_cmap('gray')) # ploting first image of training data set\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1304], cmap=plt.get_cmap('gray'))\t# ploting 135th image in training data set\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[244], cmap=plt.get_cmap('gray'))\t# ploting 2445th image of test date set\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_test[39], cmap=plt.get_cmap('gray'))\t# ploting 4th image of test data set\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2PiIyDn/D5Pxt0DnlFRGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfwO2jCdAghp",
        "colab_type": "code",
        "outputId": "6ae5947c-023d-4dc4-bf56-8ab597b14849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Print shape of dataset..it will print three tuples, namely the no. of images in dataset, height and width(60000, 28, 28)\n",
        "\n",
        "print (X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Uz0kTQAmtB",
        "colab_type": "code",
        "outputId": "60764482-62f9-4b98-b76b-213f0dcca0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Step 3: Preprocess input data for Keras\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image and pixel precision set to 32 bit\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# Step 4: Preprocess class labels\n",
        "# check shape of our class label data\n",
        "\n",
        "print (Y_train.shape)\n",
        "#We should have 10 different classes, one for each digit, but it looks like we only have a 1-dimensional array.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU5LFemhAsiA",
        "colab_type": "code",
        "outputId": "f1ead3a5-61da-4769-c39c-7f46b8ee07d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check labels for the first 10 training samples:\n",
        "print (Y_train[:10])\n",
        "# output of the form [5 0 4 1 9 2 1 3 1 4]\n",
        "#The Y_train and Y_test data are not split into 10 distinct class labels, but rather are represented as a single array with the class values."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MKhIS3vAuW9",
        "colab_type": "code",
        "outputId": "7f12edba-bfae-4c99-8cda-c5ac3c102f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n",
        "from keras.utils import np_utils\t\t#for transforming data \n",
        "\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "# check again\t\n",
        "print (Y_train.shape)\n",
        "# (60000, 10)\n",
        "print (Y_train[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDjnsR5vLdqL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### a very simple model is being created in next few lines...this is the most important part => creating a good network\n",
        "\n",
        "> refer https://keras.io/layers/core/\n",
        "\n",
        "\n",
        "### Use sequential model\n",
        ">  a Sequential model is declared as\n",
        ">>        model = Sequential()\n",
        "then dense layers are added\n",
        "\n",
        "\n",
        "> Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
        "           >>  activation is the element-wise activation function passed as the activation argument\n",
        "           >>  kernel is a weights matrix created by the layer\n",
        "           >>  bias is a bias vector created by the layer (only applicable if use_bias is True)\n",
        "      \n",
        "> adding layers (can be combined with layer declaration as well)\n",
        ">>         model = Sequential([Dense(32, input_shape=(784,)), Activation('relu'),Dense(10), Activation('softmax'),])\n",
        " \n",
        "\n",
        ">> > Or\n",
        "\n",
        ">>         model.add(Dense(32, input_dim=784))\n",
        ">>         model.add(Activation('relu'))\n",
        "\n",
        "> model needs to know what input shape it should expect\n",
        "\n",
        ">> first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape\n",
        "\n",
        "\n",
        "> Dense(32, input_dim=784) specifies that it is \n",
        "\t\t>> first (input) layer\n",
        "        \n",
        "  >> output dimension is 32 ($1^{st}$ argument \n",
        "    \n",
        ">> input dimension is 784\n",
        "\n",
        "   >> kernel_initializer: Initializations define the way to set the initial random weights of Keras layers.\n",
        "    \n",
        "   >> kernel_initializer='normal': name of initialization function for the weights of the layer. normal for values \n",
        "    \n",
        "   >> randomly drawn from normal distribution.\n",
        "   \n",
        "   >> many more intializers: Zeros, Ones, normal, Constant, normal , and many more\n",
        "    \n",
        "   >> If no activation function specified, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "\n",
        "\n",
        "> activations: Activations can either be used through an Activation layer, or through the activation argument supported by all forward layers:    \n",
        ">> many activation function are available in Keras: relu, softmax, sigmoid, tanh, so on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcp5iXTAyyZ",
        "colab_type": "code",
        "outputId": "995a371e-f8a3-4945-cdea-706361fdd1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# Define model architecture\n",
        "\n",
        "from keras.models import Sequential\t\t#model\n",
        "from keras.layers import Dense\t\t\t#layer\n",
        "from keras.layers import Dropout\t\t#layer\n",
        "from keras import initializers      # for importing initializers of keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer=initializers.RandomNormal(), activation='relu')) #only one hidden layer with relu as activation function\n",
        "#model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer=initializers.Constant(value=5), activation='relu')) #only one hidden layer with relu as activation function\t\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\t\t\t\t\t#output layer with softmax as activation function\n",
        "\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "print (\"congrts model defined...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "congrts model defined...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZOI0ZQSM-Nv",
        "colab_type": "text"
      },
      "source": [
        "### Before training, configure the learning process, using compile() method. Three argements:\n",
        "    > loss function: the objective function that model try to minimize\n",
        "          >> many more: categorical_crossentropy, mean_squared_error, mean_squared_logarithmic_error, ......\n",
        "    > optimizer: ANN training process is an optimization task with the aim of finding a set of weights to minimize some \n",
        "    > objective function\n",
        "          >> determine how weights are updated\n",
        "          >> many more: adam (Adaptive moment estimation), sgd (Stochastic gradient descent), \n",
        "    > list of metrics: used to judge performance of model, similar to objective function however not used for training purpose\n",
        "      \n",
        "### optimizer, loss function, meterics => very important step which will determine the performance of your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFg3NWWpA04y",
        "colab_type": "code",
        "outputId": "069d72cc-ab15-48db-9423-a84cf58f35f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compile model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "print (\"Compilation done ...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compilation done ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE4bnbsYNSM4",
        "colab_type": "text"
      },
      "source": [
        "> training, validation, test\n",
        "\n",
        "> multiple variations of the model is trained on the training dataset => parameter tuning\n",
        "\n",
        "> one of the variation is chosen based performance on the validation set => model selection\n",
        "\n",
        "> evaluation on test set\n",
        "\n",
        "> epoch: number of times learning algorithm sees entire data\n",
        "\n",
        "> batch size: number of samples processed before updating weights\n",
        "\n",
        "> By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch. (no information, animated bar, numbe of epochs) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSh9LnquA22y",
        "colab_type": "code",
        "outputId": "20191d6c-4a42-40cb-c271-21499f5d3cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "#Train model\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train,validation_split=0.2, epochs=10, batch_size=200, verbose=1)\n",
        "\n",
        "\n",
        "print (\"parameter tuning done...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 10s 217us/step - loss: 0.3181 - acc: 0.9094 - val_loss: 0.1682 - val_acc: 0.9526\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 11s 232us/step - loss: 0.1264 - acc: 0.9639 - val_loss: 0.1155 - val_acc: 0.9670\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 11s 235us/step - loss: 0.0823 - acc: 0.9766 - val_loss: 0.0916 - val_acc: 0.9736\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 11s 233us/step - loss: 0.0589 - acc: 0.9833 - val_loss: 0.0855 - val_acc: 0.9751\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 11s 233us/step - loss: 0.0412 - acc: 0.9894 - val_loss: 0.0790 - val_acc: 0.9753\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 11s 227us/step - loss: 0.0310 - acc: 0.9917 - val_loss: 0.0757 - val_acc: 0.9766\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 11s 235us/step - loss: 0.0225 - acc: 0.9945 - val_loss: 0.0723 - val_acc: 0.9778\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 11s 232us/step - loss: 0.0169 - acc: 0.9963 - val_loss: 0.0718 - val_acc: 0.9798\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 11s 229us/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.0703 - val_acc: 0.9803\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 11s 232us/step - loss: 0.0090 - acc: 0.9986 - val_loss: 0.0787 - val_acc: 0.9780\n",
            "parameter tuning done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_u0OQ53A4_x",
        "colab_type": "code",
        "outputId": "ec533a76-712c-440f-e74c-49fcfa5c2937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Step 8: Evaluate model\n",
        "scores = model.evaluate(X_test, Y_test)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 148us/step\n",
            "Error: 2.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyVr7wpzBAMt",
        "colab_type": "text"
      },
      "source": [
        "**Additional**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "=> Improving Performance of Simple Network: additional hidden layers (add one more dense layer)\n",
        " \n",
        "     model.add(Dense(num_classes, kernel_initializer='normal', activation='relu'))\n",
        "     \n",
        "=> Improving Performance of Simple Network: additional hidden layers (add one more dense layer)\n",
        "\n",
        "     model.add(Dense(num_classes, kernel_initializer='normal', activation='tanh'))\n",
        "\n",
        "=> Improving Performance of Simple Network: introducing dropout layer\n",
        "\n",
        "      model.add(Dropout(0.2))\n",
        "\n",
        "=> Improving Performance of Simple Network: using different optimizers: SGD, Adagrad,Adam...\n",
        "\n",
        "=> Improving Performance of Simple Network: training for more number of epochs (20)\n",
        "\n",
        "=> other options to explore\n",
        "\n",
        "\n",
        "> different learning rate for optimizer\n",
        "\n",
        "> number of neurons in hidden layer\n",
        "\n",
        "> batch size\n",
        "\n",
        "> with different optimizers\n",
        "   \n",
        "> Increasing the number of internal hidden neurons\n",
        "   \n",
        "  \n",
        "=> steps to follow to make an efficient image classifier?\n",
        "     \n",
        "     >lot of experimentation and testing to get the optimal structure and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa-y7lxnm0t5",
        "colab_type": "code",
        "outputId": "78ad0002-bef8-4f82-a51f-801496b16caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#printing metrices\n",
        "print(model.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TTXar8dFT7Z",
        "colab_type": "code",
        "outputId": "fe5028dd-2e55-45b0-80c5-f2b572191ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# print summary of the model\n",
        "print (model.summary())\n",
        "\n",
        "# for more on model visualization you may refer to https://keras.io/visualization/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
